{"cells":[{"cell_type":"markdown","metadata":{"id":"a_ZamPiA-1jB"},"source":["# **環境設定**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16454,"status":"ok","timestamp":1709027949197,"user":{"displayName":"Alyssa Ku","userId":"04018782521843085767"},"user_tz":-480},"id":"30dB_35Q8TPx","outputId":"b0fff3bc-b10a-4263-87ac-21f74ca629ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.1.19 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.5/107.7 GB disk)\n"]}],"source":["#安裝套件與引用yolo\n","!pip install ultralytics\n","\n","from IPython import display\n","display.clear_output()\n","from IPython.display import display, Image\n","\n","import ultralytics\n","ultralytics.checks()\n","from ultralytics import YOLO"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11560,"status":"ok","timestamp":1709028024782,"user":{"displayName":"Alyssa Ku","userId":"04018782521843085767"},"user_tz":-480},"id":"Hj2FEF498qAK","outputId":"531b59d7-bd8c-44c4-bf6f-ce9db7e09177"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/datasets\n","Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.20)\n","Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n","Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n","Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.18.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.49.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in test_1112_01_apical-lesion_multi-1 to yolov8-obb:: 100%|██████████| 1200/1200 [00:00<00:00, 1368.86it/s]"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to test_1112_01_apical-lesion_multi-1 in yolov8-obb:: 100%|██████████| 280/280 [00:00<00:00, 8570.86it/s]\n"]}],"source":["#建立資料集路徑，記得替換{HOME}\n","HOME= '/content'\n","!mkdir {HOME}/datasets\n","%cd {HOME}/datasets\n","\n","#下載roboflow套件並引入自定義圖片(查看說明文件第一點)\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"your api key\")\n","project = rf.workspace(\"project-tx2ls\").project(\"test_1112_01_apical-lesion_multi\")\n","dataset = project.version(1).download(\"yolov8-obb\")"]},{"cell_type":"markdown","metadata":{"id":"eW4hXuU_-_hH"},"source":["# **訓練自定義模型**\n","查看說明文件第二點更改設定(data.yaml)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2FqV_xp6-bkJ","outputId":"e2a5a388-c9e2-4001-8124-910d5a9eb31c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s-obb.pt to 'yolov8s-obb.pt'...\n","100% 22.2M/22.2M [00:00<00:00, 46.4MB/s]\n","Ultralytics YOLOv8.1.19 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolov8s-obb.pt, data=/content/datasets/test_1112_01_apical-lesion_multi-1/data.yaml, epochs=10, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/obb/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 5.05MB/s]\n","2024-02-27 10:03:45.154631: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-27 10:03:45.154709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-27 10:03:45.156491: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=15 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2402614  ultralytics.nn.modules.head.OBB              [1, 1, [128, 256, 512]]       \n","YOLOv8s-obb summary: 250 layers, 11422166 parameters, 11422150 gradients, 29.6 GFLOPs\n","\n","Transferred 391/397 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/obb/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/test_1112_01_apical-lesion_multi-1/train/labels... 115 images, 0 backgrounds, 0 corrupt: 100% 115/115 [00:00<00:00, 1378.61it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/test_1112_01_apical-lesion_multi-1/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/test_1112_01_apical-lesion_multi-1/valid/labels... 13 images, 0 backgrounds, 0 corrupt: 100% 13/13 [00:00<00:00, 1402.09it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/test_1112_01_apical-lesion_multi-1/valid/labels.cache\n","Plotting labels to runs/obb/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/obb/train\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10         0G      2.108      3.909      3.602         13        640:  53% 8/15 [02:37<02:08, 18.36s/it]"]}],"source":["# mode=train\n","%cd {HOME}\n","\n","!yolo task=obb mode=train model=yolov8s-obb.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 batch=8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wmmWFoAo_Gf9"},"outputs":[],"source":["# 查看訓練結果，記得注意路徑\n","%cd {HOME}\n","Image(filename=f'{HOME}/runs/obb/train2/confusion_matrix.png', width=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQbLAcZA_m90"},"outputs":[],"source":["# mode=val，記得注意路徑\n","%cd {HOME}\n","\n","!yolo task=obb mode=val model={HOME}/runs/obb/train2/weights/best.pt data={dataset.location}/data.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7qTjHE4_rWB"},"outputs":[],"source":["# mode=predict，記得注意路徑\n","%cd {HOME}\n","!yolo task=obb mode=predict model={HOME}/runs/obb/train2/weights/best.pt conf=0.5 source={dataset.location}/test/images save=true"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zt5wh1xb_8kT"},"outputs":[],"source":["# 將測試結果一張張輸出給我們看\n","import glob\n","from IPython.display import Image, display\n","\n","for image_path in glob.glob(f'{HOME}/runs/obb/predict/*.jpg'):\n","      display(Image(filename=image_path))\n","      print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"G0YxGHSo-7-K"},"source":["# **額外功能**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fINzKskJ86EL"},"outputs":[],"source":["#這格選用 他是為了把之前的yolov5 OBB 轉 yolov8 OBB，現在roboflow已經有相關的匯出支援(若我們更改使用工具可能會用到)\n","import os\n","\n","# Define the classes and their corresponding indices\n","class_names = ['0: apical_lesion']\n","class_indices = {name: index for index, name in enumerate(class_names)}\n","\n","\n","# Image dimensions\n","img_width, img_height = 640, 640\n","\n","# Path to the folder containing the annotation files\n","folder_path = '/content/datasets/test_1112_01_apical-lesion_multi-1/valid/labels'\n","\n","# Function to normalize coordinates\n","def normalize_coordinates(coord, max_value):\n","    return float(coord) / max_value\n","\n","# Process each file in the folder\n","for filename in os.listdir(folder_path):\n","    if filename.endswith(\".txt\"):  # assuming the annotation files are .txt files\n","        file_path = os.path.join(folder_path, filename)\n","        with open(file_path, 'r') as file:\n","            lines = file.readlines()\n","\n","\n","        new_lines = []\n","        for line in lines:\n","            parts = line.strip().split(' ')\n","            if len(parts) == 10:\n","                # Extract label and coordinates\n","                label = parts[-2]\n","                coords = parts[:8]\n","\n","                # Get the class index\n","                class_index = class_indices.get(label, -1)\n","                if class_index != -1:\n","                    # Normalize coordinates\n","                    normalized_coords = [normalize_coordinates(coords[i], img_width if i % 2 == 0 else img_height) for i in range(8)]\n","\n","                    # Convert to the desired format and add to new lines\n","                    new_line = f\"{class_index} \" + \" \".join(map(str, normalized_coords))\n","                    new_lines.append(new_line)\n","\n","        # Write the converted lines to a new file or overwrite the existing file\n","        with open(file_path, 'w') as file:\n","            file.write('\\n'.join(new_lines))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMp1+18jihB98z4P1BHkiqE","collapsed_sections":["G0YxGHSo-7-K"],"provenance":[{"file_id":"1rDbtQaqA31cO0kYXiGlTQcxI1jfv3Azh","timestamp":1709028403386}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
